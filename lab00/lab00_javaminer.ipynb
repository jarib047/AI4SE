{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46e9b0a-ea74-4d2a-8e67-21e81943d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import shutil\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import stat\n",
    "import errno\n",
    "import pandas as pd\n",
    "import javalang\n",
    "\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "# API Endpoints\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "SEARCH_REPOS_ENDPOINT = f\"{GITHUB_API_URL}/search/repositories\"\n",
    "\n",
    "# Target data sizes\n",
    "TARGET_TRAIN_SIZE = 25000\n",
    "TARGET_TEST_SIZE = 5000\n",
    "TOTAL_TARGET_SIZE = TARGET_TRAIN_SIZE + TARGET_TEST_SIZE\n",
    "\n",
    "def search_java_repos(query, per_page=100, pages=1):\n",
    "    \"\"\"\n",
    "    Searches for popular Java repositories on GitHub based on stars.\n",
    "    \"\"\"\n",
    "    repos = []\n",
    "    headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"} if GITHUB_TOKEN else {} \n",
    "    for page in range(1, pages + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"sort\": \"stars\",\n",
    "            \"order\": \"desc\",\n",
    "            \"per_page\": per_page,\n",
    "            \"page\": page\n",
    "        }        \n",
    "        try:\n",
    "            response = requests.get(SEARCH_REPOS_ENDPOINT, headers=headers, params=params)\n",
    "            response.raise_for_status() # Raise an exception for bad status codes            \n",
    "            data = response.json()\n",
    "            items = data.get(\"items\", [])\n",
    "            repos.extend(items)            \n",
    "            print(f\"Found {len(items)} repositories on page {page}.\")\n",
    "            time.sleep(1)           \n",
    "        except Exception as e:\n",
    "            print(f\"Error searching for repositories: {e}\")\n",
    "            break\n",
    "    return repos\n",
    "\n",
    "\n",
    "def clone_repo(repo_url, clone_dir):\n",
    "    \"\"\"\n",
    "    Clones a repository to a local directory.\n",
    "    \"\"\"\n",
    "    print(f\"Cloning repository from '{repo_url}'...\")\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", repo_url, clone_dir], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"Successfully cloned to '{clone_dir}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cloning repository: {e}\")\n",
    "\n",
    "        \n",
    "def get_latest_commit_sha(repo_dir):\n",
    "    \"\"\"\n",
    "    Gets the latest commit SHA for a cloned repository.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"],\n",
    "            cwd=repo_dir,\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting commit SHA for {repo_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "        \n",
    "def get_java_files_local(repo_dir):\n",
    "    \"\"\"\n",
    "    Finds all .java files in a local directory.\n",
    "    \"\"\"\n",
    "    java_files = []\n",
    "    for root, _, files in os.walk(repo_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".java\"):\n",
    "                java_files.append(os.path.join(root, file))\n",
    "    return java_files\n",
    "\n",
    "def cleanup_repo(repo_dir):\n",
    "    \"\"\"\n",
    "    Deletes the local repository directory.\n",
    "    \"\"\"\n",
    "    print(f\"Cleaning up: Deleting '{repo_dir}'.\")\n",
    "    try:\n",
    "        shutil.rmtree(repo_dir, onerror=on_rm_error)\n",
    "        print(\"Cleanup successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting directory: {e}\")\n",
    "\n",
    "        \n",
    "def parse_java_methods(java_code):\n",
    "    \"\"\"\n",
    "    Parses Java code by tracking curly brace nesting to extract methods.\n",
    "    \"\"\"\n",
    "    methods = []\n",
    "    lines = java_code.splitlines()\n",
    "    \n",
    "    # This regex is now only used to find the start of a method signature.\n",
    "    method_signature_regex = re.compile(\n",
    "        r'^\\s*(?:public|protected|private|static|final|\\s)+[\\w<>\\.\\s,\\[\\]]+\\s+(\\w+)\\s*\\(.*?\\)\\s*(?:throws\\s+[\\w\\s,]+)?\\s*\\{',\n",
    "        re.MULTILINE | re.DOTALL\n",
    "    )\n",
    "    current_line_number = 0\n",
    "    while current_line_number < len(lines):\n",
    "        line = lines[current_line_number]\n",
    "        match = method_signature_regex.search(line)\n",
    "        if match:\n",
    "            brace_count = 1\n",
    "            start_line_number = current_line_number + 1\n",
    "            signature = line.strip()\n",
    "            while not signature.endswith('{') and current_line_number + 1 < len(lines):\n",
    "                current_line_number += 1\n",
    "                signature += \" \" + lines[current_line_number].strip()\n",
    "            signature = signature.strip().rstrip('{').strip()\n",
    "            method_name = match.group(1)\n",
    "            original_code_lines = [lines[start_line_number-1]]\n",
    "            i = start_line_number\n",
    "            while i < len(lines):\n",
    "                current_line = lines[i]\n",
    "                original_code_lines.append(current_line)\n",
    "                brace_count += current_line.count('{')\n",
    "                brace_count -= current_line.count('}')\n",
    "                if brace_count == 0:\n",
    "                    end_line_number = i + 1\n",
    "                    original_code = \"\\n\".join(original_code_lines).strip()\n",
    "                    code_tokens = original_code.split()\n",
    "                    methods.append({\n",
    "                        \"method_name\": method_name,\n",
    "                        \"start_line\": start_line_number,\n",
    "                        \"end_line\": end_line_number,\n",
    "                        \"signature\": signature,\n",
    "                        \"original_code\": original_code,\n",
    "                        \"code_tokens\": \" \".join(code_tokens)\n",
    "                    })\n",
    "                    current_line_number = i\n",
    "                    break\n",
    "                i += 1\n",
    "        current_line_number += 1  \n",
    "    return methods\n",
    "\n",
    "\n",
    "def write_data_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    Writes a list of data dictionaries to a single CSV file.\n",
    "    \"\"\"\n",
    "    print(f\"Writing {len(data)} entries to '{filename}'.\")\n",
    "    fieldnames = [\n",
    "        \"dataset_split\", \"repo_name\", \"repo_url\", \"commit_sha\", \n",
    "        \"file_path\", \"method_name\", \"start_line\", \"end_line\", \n",
    "        \"signature\", \"original_code\", \"code_tokens\"\n",
    "    ]\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    print(f\"Successfully wrote data to '{filename}'.\")\n",
    "\n",
    "\n",
    "def tokenize_java(code):\n",
    "    \"\"\"\n",
    "    Tokenizes a Java code string using javalang.\n",
    "    Returns a list of tokens as strings.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokens = list(javalang.tokenizer.tokenize(code))\n",
    "        return [t.value for t in tokens]\n",
    "    except:\n",
    "        # return empty list if tokenization fails\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435f3960-5837-464a-b3a9-f38ab6fbc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # if not GITHUB_TOKEN:\n",
    "    #     print(\"Warning: GITHUB_TOKEN environment variable not set. Rate limits will be very strict.\")\n",
    "    #     print(\"Please set your token to run this script effectively.\")    \n",
    "    all_methods = []\n",
    "    seen_methods = set()\n",
    "    query = \"language:Java\"\n",
    "    repos = search_java_repos(query, pages=1)\n",
    "    if not repos:\n",
    "        print(\"No repositories found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    java_keywords = {\"class\", \"public\", \"private\", \"protected\", \"static\", \"void\", \"String\", \"int\", \"double\", \"boolean\", \"if\", \n",
    "                     \"else\", \"for\", \"while\", \"return\"}\n",
    "    for repo in repos:\n",
    "        if len(all_methods) >= TOTAL_TARGET_SIZE:\n",
    "            print(f\"Method count reached {TOTAL_TARGET_SIZE}. Stopping further repository processing.\")\n",
    "            break     \n",
    "        repo_name = repo[\"full_name\"]\n",
    "        repo_url = repo[\"html_url\"]\n",
    "        repo_dir = f\"./cloned_repos/{repo_name.replace('/', '_')}\"\n",
    "        print(f\"\\n--- Processing repository: {repo_name} ---\")\n",
    "        \n",
    "        # Clone the queried repos \n",
    "        clone_repo(repo_url, repo_dir)\n",
    "        if os.path.exists(repo_dir):\n",
    "            # Get the latest commit SHA\n",
    "            latest_sha = get_latest_commit_sha(repo_dir)\n",
    "            # Find the cloned repos in local directory\n",
    "            java_files = get_java_files_local(repo_dir)\n",
    "            if not java_files:\n",
    "                print(\"No Java files found. Skipping to next repo.\")\n",
    "                cleanup_repo(repo_dir)\n",
    "                continue  \n",
    "            for file_path in java_files:\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        java_code = f.read()\n",
    "                        methods = parse_java_methods(java_code)\n",
    "                        for method in methods:\n",
    "                            # Create a unique identifier to check for duplicates\n",
    "                            unique_id = f\"{repo_name}_{file_path.replace(repo_dir + os.sep, '')}_{method['signature']}\"\n",
    "                            if unique_id in seen_methods:\n",
    "                                continue\n",
    "                            code_tokens = set(method[\"original_code\"].split())\n",
    "                            if not code_tokens.intersection(java_keywords):\n",
    "                                continue\n",
    "                            all_methods.append({\n",
    "                                \"repo_name\": repo_name,\n",
    "                                \"repo_url\": repo_url,\n",
    "                                \"commit_sha\": latest_sha,\n",
    "                                \"file_path\": file_path.replace(repo_dir + os.sep, \"\"),\n",
    "                                **method\n",
    "                            })\n",
    "                            seen_methods.add(unique_id)            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading file '{file_path}': {e}\")\n",
    "            \n",
    "            # Delete the cloned repository after processing\n",
    "            cleanup_repo(repo_dir)\n",
    "            \n",
    "    # Check if data count exceeds the required count\n",
    "    if len(all_methods) < TOTAL_TARGET_SIZE:\n",
    "        print(f\"\\nCould only collect {len(all_methods)} methods, which is less than the target of {TOTAL_TARGET_SIZE}.\")\n",
    "        print(\"Try increasing the query size.\")        \n",
    "    else:\n",
    "        # Shuffle the methods to ensure a random distribution\n",
    "        random.shuffle(all_methods)\n",
    "        # Add the 'dataset_split' field and write to a single CSV\n",
    "        for i, method in enumerate(all_methods[:TOTAL_TARGET_SIZE]):\n",
    "            if i < TARGET_TRAIN_SIZE:\n",
    "                method[\"dataset_split\"] = \"train\"\n",
    "            else:\n",
    "                method[\"dataset_split\"] = \"test\"      \n",
    "        write_data_to_csv(all_methods[:TOTAL_TARGET_SIZE], \"methods1.csv\")  \n",
    "\n",
    "    #tokenize the collected methods\n",
    "    df = pd.read_csv(\"methods1.csv\")\n",
    "    df['tokenized_code'] = df['original_code'].apply(tokenize_java)\n",
    "    df.to_csv(\"methods_tokenized1.csv\", index=False)\n",
    "    print(\"\\n--- Process finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ec1d2d-1d88-472a-9c82-351ad40d6021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 repositories on page 1.\n",
      "\n",
      "--- Processing repository: Snailclimb/JavaGuide ---\n",
      "Cloning repository from 'https://github.com/Snailclimb/JavaGuide'...\n",
      "Successfully cloned to './cloned_repos/Snailclimb_JavaGuide'.\n",
      "No Java files found. Skipping to next repo.\n",
      "Cleaning up: Deleting './cloned_repos/Snailclimb_JavaGuide'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: krahets/hello-algo ---\n",
      "Cloning repository from 'https://github.com/krahets/hello-algo'...\n",
      "Successfully cloned to './cloned_repos/krahets_hello-algo'.\n",
      "Cleaning up: Deleting './cloned_repos/krahets_hello-algo'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: GrowingGit/GitHub-Chinese-Top-Charts ---\n",
      "Cloning repository from 'https://github.com/GrowingGit/GitHub-Chinese-Top-Charts'...\n",
      "Successfully cloned to './cloned_repos/GrowingGit_GitHub-Chinese-Top-Charts'.\n",
      "Cleaning up: Deleting './cloned_repos/GrowingGit_GitHub-Chinese-Top-Charts'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: iluwatar/java-design-patterns ---\n",
      "Cloning repository from 'https://github.com/iluwatar/java-design-patterns'...\n",
      "Successfully cloned to './cloned_repos/iluwatar_java-design-patterns'.\n",
      "Cleaning up: Deleting './cloned_repos/iluwatar_java-design-patterns'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: macrozheng/mall ---\n",
      "Cloning repository from 'https://github.com/macrozheng/mall'...\n",
      "Successfully cloned to './cloned_repos/macrozheng_mall'.\n",
      "Cleaning up: Deleting './cloned_repos/macrozheng_mall'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: spring-projects/spring-boot ---\n",
      "Cloning repository from 'https://github.com/spring-projects/spring-boot'...\n",
      "Error cloning repository: Command '['git', 'clone', '--depth', '1', 'https://github.com/spring-projects/spring-boot', './cloned_repos/spring-projects_spring-boot']' returned non-zero exit status 128.\n",
      "Cleaning up: Deleting './cloned_repos/spring-projects_spring-boot'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: doocs/advanced-java ---\n",
      "Cloning repository from 'https://github.com/doocs/advanced-java'...\n",
      "Successfully cloned to './cloned_repos/doocs_advanced-java'.\n",
      "Cleaning up: Deleting './cloned_repos/doocs_advanced-java'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: MisterBooo/LeetCodeAnimation ---\n",
      "Cloning repository from 'https://github.com/MisterBooo/LeetCodeAnimation'...\n",
      "Successfully cloned to './cloned_repos/MisterBooo_LeetCodeAnimation'.\n",
      "Error reading file './cloned_repos/MisterBooo_LeetCodeAnimation\\0004-median-of-two-sorted-arrays\\Code\\1.java': 'utf-8' codec can't decode byte 0xb3 in position 107: invalid start byte\n",
      "Error reading file './cloned_repos/MisterBooo_LeetCodeAnimation\\0215-Kth-Largest-Element-in-an-Array\\Code\\1.java': 'utf-8' codec can't decode byte 0xb4 in position 84: invalid start byte\n",
      "Error reading file './cloned_repos/MisterBooo_LeetCodeAnimation\\0946--validate-stack-sequences\\Code\\1.java': 'utf-8' codec can't decode byte 0xb6 in position 363: invalid start byte\n",
      "Cleaning up: Deleting './cloned_repos/MisterBooo_LeetCodeAnimation'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "\n",
      "--- Processing repository: elastic/elasticsearch ---\n",
      "Cloning repository from 'https://github.com/elastic/elasticsearch'...\n",
      "Successfully cloned to './cloned_repos/elastic_elasticsearch'.\n",
      "Cleaning up: Deleting './cloned_repos/elastic_elasticsearch'.\n",
      "Error deleting directory: name 'on_rm_error' is not defined\n",
      "Method count reached 30000. Stopping further repository processing.\n",
      "Writing 30000 entries to 'methods1.csv'.\n",
      "Successfully wrote data to 'methods1.csv'.\n",
      "\n",
      "--- Process finished ---\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create the directory to store cloned repositories\n",
    "    if not os.path.exists(\"./cloned_repos\"):\n",
    "        os.makedirs(\"./cloned_repos\")   \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
